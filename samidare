#!/usr/bin/env ruby

$KCODE = 'e'

require 'xtemplate'
require 'open-uri'
require 'uri'
require 'time'
require 'resolv-replace'
require 'yaml'
require 'tidy'
require 'mconv'
require 'timeout'
require 'net/http'
require 'pp'
require 'optparse'
require 'rexml/document'
require 'zlib'
require 'lirs'
require 'autofile'
require 'htree'
require 'string-util'

CONFIG_FILENAME = 'config.yml'
STATUS_FILENAME = 'status.rm'

TEMPLATE_LATEST_FILENAME = 't.latest.html'
OUTPUT_LATEST_FILENAME = 'latest.html'

AutoFile.directory = 'tmp' # xxx: should be configurable.

def Time.httpdate_robust(str)
  Time.httpdate(str) rescue Time.parse(str)
end

class Entry
  ENTRIES = {}

  def initialize(hash, config)
    @hash = hash
    @config = config
    ENTRIES[@hash['URI']] = self
    ENTRIES[@hash['LinkURI']] = self if @hash['LinkURI']
  end
  attr_reader :hash
  attr_reader :config

  def update_info?
    @config.include? 'UpdateInfo'
  end

  def should_check?
    ARGV.empty? or
    ARGV.include?(@config['URI']) or
    @config['LinkURI'] && ARGV.include?(@config['LinkURI']) or
    @hash['_update_info']
  end

  DefaultMinimumInterval = 5 * 60
  DefaultMaximumInterval = 24 * 60 * 60
  def timing_check
    t1 = next_timing
    t2 = Time.now
    t1 <= t2
  end

  def expect_next_by_periodical
    h = find_last_200
    return nil unless h
    periodical = h['periodical']
    return nil unless periodical 
    return nil if periodical.length < 2
    last_modified = periodical.last
    intervals = []
    prev = nil
    periodical.each {|curr|
      intervals << curr - prev if prev
      prev = curr
    }
    t = last_modified + intervals.min
    begin # adjust server/client time difference
      t += (h['clientDateEnd'] || h['clientDateBeg']) - Time.httpdate_robust(h['serverDateString'])
    rescue
    end
    t
  end

  def next_timing
    if @hash['_update_info']
      Time.now
    elsif e1 = find_first_error
      min = @config.fetch('MinimumInterval', DefaultMinimumInterval) # xxx: should support units other than second.
      e2 = find_last_error
      e1t = e1['clientDateEnd']
      e2t = e2['clientDateEnd']
      if e1.equal? e2
        e1t + min
      else
        e2t + (e2t - e1t)
      end
    elsif s1 = find_first_200_with_current_content # Is there any 200?
      min = @config.fetch('MinimumInterval', DefaultMinimumInterval) # xxx: should support units other than second.
      max = @config.fetch('MaximumInterval', DefaultMaximumInterval)
      min = max if max < min

      s2 = find_last_success
      s2t = s2['clientDateEnd'] || s2['clientDateBeg']

      if @config['Periodical']
        s1t = expect_next_by_periodical
        return s1t if s1t && s2t < s1t
      end
      if !s1t
        begin
          s1t = Time.httpdate_robust(s1['lastModifiedString']) +
            ((s1['clientDateEnd'] || s1['clientDateBeg']) - Time.httpdate_robust(s1['serverDateString']))
        rescue
          s1t = s1['clientDateEnd'] || s1['clientDateBeg']
        end
        s1t = s2t if s2t < s1t
      end

      r = s2t + (s2t - s1t)
      if r < s2t + min
        s2t + min
      elsif s2t + max < r
        s2t + max
      else
        r
      end
    else
      Time.now
    end
  end

  def check
    uri = @config['URI']
    @hash['_log'] = [] unless @hash['_log']
    logseq = @hash['_log']

    log = @config.dup

    log['clientDateBeg'] = client_date_1 = Time.now
    STDERR.puts "#{client_date_1.iso8601} fetch start #{uri}" if $VERBOSE
    page, meta = fetch(log)
    log['clientDateEnd'] = client_date_2 = Time.now
    STDERR.puts "#{client_date_2.iso8601} fetch end #{log['trouble'] || "#{log['status']} #{log['statusMessage']}"} #{uri}" if $VERBOSE

    examine(page, meta, log) if page

    add_log(log)
    @hash.delete '_update_info'
  end

  def fetch(log)
    uri = @config['URI']
    opts = {"User-Agent"=>"samidare"}
    if h = find_last_200 and @hash['_log'].last['status'] != '412'
      # publicfile rejects requests which have If-None-Match as:
      #   412 I do not accept If-None-Match
      # Since 412 means `Precondition Failed', samidare tries request without
      # precondition.  If it success, samidare may know new valid condition.
      # For example apache is replaced with publicfile,
      # ETag should be forgotten.  Above 412 handling handle this case.
      if @config.fetch('UseIfModifiedSince', true)
        opts['If-Modified-Since'] = h['lastModifiedString'] if h['lastModifiedString']
      end
      opts['If-None-Match'] = h['eTag'] if h['eTag']
    end
    #PP.pp([uri, opts], STDERR) if $VERBOSE
    page = nil
    meta = nil
    status = nil
    status_message = nil
    trouble = nil
    begin
      page = timeout(@config['Timeout'] || 200) { URI.parse(uri).read(opts) }
      meta = page.meta
      status = page.status[0]
      status_message = page.status[1]
    rescue OpenURI::HTTPError
      if $!.io.status.first == '304'
        meta = $!.io.meta
        status = $!.io.status[0]
        status_message = $!.io.status[1]
      else
        meta = $!.io.meta
        status = $!.io.status[0]
        status_message = $!.io.status[1]
        trouble = "#{status} #{status_message}"
      end
    rescue StandardError, TimeoutError
      trouble = $!.message
    end

    log['status'] = status
    log['statusMessage'] = status_message if status_message
    log['serverDateString'] = meta['date'] if meta && meta['date']
    log['trouble'] = trouble if trouble

    if @config['LogMeta']
      log['logSendHeader'] = opts
      log['logRecvHeader'] = meta
    end

    return page, meta
  end

  def examine(page, meta, log)
    uri = @config['URI']
    log['baseURI'] = page.base_uri.to_s if page.base_uri.to_s != uri
    log['lastModifiedString'] = meta['last-modified'] if meta['last-modified']
    log['eTag'] = meta['etag'] if meta['etag']
    content_type = log['contentType'] = page.content_type if page.content_type
    content_charset = page.charset { @config['DefaultCharset'] || page.guess_charset }
    content_charset = content_charset.downcase
    log['contentCharset'] = content_charset

    content, content_encoding = decode_content_encoding(page, log)
    log['content'] = AutoFile.new(uri, content, content_type)

    # checksum for gzip/deflate decoded content.
    # compression level is not affected.
    log['checksum'] = content.sum

    if !content_encoding && %r{\A(?:text/html|text/xml)\z} =~ content_type
      t = HTree.parse(content.decode_charset(content_charset))

      title = t.title
      log['extractedTitle'] = title if title

      author = t.author
      log['extractedAuthor'] = author if author

      if ignore_path = @config['IgnorePath']
        ignore_path = ignore_path.split(/\s+/)
      else
        ignore_path = []
      end
      ignore_pattern = path2pattern(*ignore_path)
      t = t.filter_with_path {|e, path|
        not ( 
          (HTree::Elem === e && (e.tagname == 'style' ||
                                 e.tagname == 'script')) ||
          ignore_pattern =~ path
        )
      }
      log['checksum_filtered'] = t.rcdata.sum
      log['checksum_filter'] = ['IgnorePath', *ignore_path] if !ignore_path.empty?
    end

    if !content_encoding
      case @config['UpdateInfo']
      when 'lirs'
        check_lirs(content)
      when 'html'
        check_html(log)
      end
    end
  end

  def path2pattern(*paths)
    Regexp.alt *paths.map {|path|
      Regexp.new(path.gsub(%r{[^/]+}) {|step|
        if /\[\d+\]\z/ =~ step
          Regexp.quote(step)
        else
          Regexp.quote(step) + '(\[\d+\])?'
        end
      })
    }
  end

  def decode_content_encoding(page, log)
    content = page
    if page.content_encoding.empty?
      if /\A\x1f\x8b/ =~ content # gziped?
        begin
          content = content.decode_gzip
        rescue Zlib::BufError
        end
      end
    else
      content_encoding = page.content_encoding.dup
      while !content_encoding.empty?
        case content_encoding.last
        when 'gzip', 'x-gzip'
          begin
            content = content.decode_gzip
          rescue Zlib::BufError
            break
          end
        when 'deflate'
          content = content.decode_deflate
        else
          break
        end
        content_encoding.pop
      end
      content_encoding = nil if content_encoding.empty?
      log['contentEncoding'] = content_encoding if content_encoding
    end
    return content, content_encoding
  end

  def check_lirs(new_lirs)
    log = @hash['_log']
    old_lirs = nil
    log.reverse_each {|h|
      if h['content']
        old_lirs = h['content'].content
        break
      end
    }
    begin
      l1 = LIRS.decode(old_lirs) if old_lirs
      l2 = LIRS.decode(new_lirs)
      count_all = 0
      count_interest = 0
      count_update = 0
      l2.each {|r2|
        count_all += 1
        uri = r2.target_url
        if e = ENTRIES[uri]
          count_interest += 1
          if !old_lirs or (r1 = l1[uri] and r1.last_modified != r2.last_modified)
            t1 = Time.at(r1.last_modified.to_i) if old_lirs
            t2 = Time.at(r2.last_modified.to_i)
            if e.find_last_success['clientDateEnd'] < t2 #xxx: not so acculate.
              count_update += 1
              p [:LIRS_UPDATE, uri, t1, t2, @config['URI']]
              ENTRIES[uri].hash['_update_info'] = true
            end
          end
        end
      }
      STDERR.puts "LIRS total: #{count_update} / #{count_interest} / #{count_all} - #{@config['URI']}" if $VERBOSE
    rescue
      # External update information is a just hint.
      # So it is ignorable even if it has some trouble.
    end
  end

  #xxx: rescue
  def check_html(new_log)
    new_check_key = extract_html_check_key(new_log)
    old_log = find_last_200
    old_check_key = old_log ? extract_html_check_key(old_log) : {}
    updated_uris = {}
    (new_check_key.keys - old_check_key.keys).each {|uri|
      p [:HTML_UPDATE, uri, @config['URI']]; STDOUT.flush
      updated_uris[uri] = true
    }
    (new_check_key.keys & old_check_key.keys).each {|uri|
      if old_check_key[uri] != new_check_key[uri]
        p [:HTML_UPDATE, uri, @config['URI'],
            "#{Mconv.conv(old_check_key[uri], Mconv.internal_mime_charset, 'UTF-8')}",
            "#{Mconv.conv(new_check_key[uri], Mconv.internal_mime_charset, 'UTF-8')}"]
        STDOUT.flush
        updated_uris[uri] = true
      end
    }
    updated_uris.each_key {|uri|
      ENTRIES[uri].hash['_update_info'] = true
    }
    STDERR.puts "HTML total: #{updated_uris.size} / #{new_check_key.size} - #{@config['URI']}" if $VERBOSE
  end

  def extract_html_check_key(log)
    return {} unless log.include?('content')
    content = log['content'].content

    entry_xpath = @config.fetch("UpdateEntry", "//a")
    check_xpath = @config.fetch("UpdateCheck", ".")

    uri_set = {}
    t = Mconv.conv(content, 'UTF-8', log['contentCharset'])
    t = Tidy.parse_string(t, "output-xml"=>true, :encoding=>"UTF-8", :wrap=>nil).dump
    t.gsub!(%r{<\n\/}, '</')
    doc = REXML::Document.new(t)
    base_uri = URI.parse(log['baseURI'] || log['URI'])
    if base_element = doc.get_elements("//base").first
      base_uri = base_uri + URI.parse(base_element.attribute("href").to_s)
    end
    doc.each_element(entry_xpath) {|entry|
      uris = []
      if entry.name == 'a'
        e = entry
        uri = (base_uri + URI.parse(e.attribute("href").to_s)).to_s
        uris << uri if uri && ENTRIES.include?(uri)
      else
        entry.each_element(".//a") {|e|
          uri = (base_uri + URI.parse(e.attribute("href").to_s)).to_s
          uris << uri if uri && ENTRIES.include?(uri)
        }
      end
      unless uris.empty?
        check = ''
        REXML::XPath.each(entry, check_xpath) {|n| n.write check }
        uris.each {|uri| uri_set[uri] = check }
      end
    }
    uri_set
  end

  StatusMap = {
    '200' => 's', # Success
    '304' => 'n', # Not-Modified
  }
  StatusMap.default = 'e' # Error

  MaxPeriodicalNum = 10
  def add_periodical_info(h)
    return if h['status'] != '200'

    log = @hash['_log']

    periodical = nil
    log.reverse_each {|l|
      if l['periodical']
        periodical = l['periodical'].dup
        break
      end
    }
    periodical ||= []

    begin
      t = Time.httpdate_robust(h['lastModifiedString'])
    rescue
    end

    if t && (periodical.empty? || periodical.last != t)
      periodical << t
    end

    if MaxPeriodicalNum < periodical.length
      periodical = periodical[(-MaxPeriodicalNum)..(-1)]
    end

    h['periodical'] = periodical if !periodical.empty?
  end

  def content_unchanged(log1, log2)
    return true if log1['checksum'] &&
                   log2['checksum'] &&
                   log1['checksum'] == log2['checksum']
    return true if log1['checksum_filtered'] &&
                   log2['checksum_filtered'] &&
                   log1['checksum_filter'] == log2['checksum_filter'] &&
                   log1['checksum_filtered'] == log2['checksum_filtered']
    false
  end

  def add_log(log)
    @hash['_log'] = [] unless @hash['_log']

    #add_periodical_info(log) if @config['Periodical']
    add_periodical_info(log)

    logseq = @hash['_log']

    case StatusMap[log['status']]
    when 'e'
      history = logseq.map {|l| StatusMap[l['status']] }.join + ' ' + StatusMap[log['status']]
      if /ee e/ =~ history
        logseq.pop
      end
      logseq << log
    when 's', 'n'
      logseq.reject! {|l| StatusMap[l['status']] == 'e' }
      logseq.shift while !logseq.empty? && StatusMap[logseq.first['status']] == 'n'

      logseq << log

      #pp logseq.map {|l| StatusMap[l['status']] + "#{l['checksum']}" }
      logs = [[]]
      logseq.each {|l|
        if logs.last.empty?
          logs.last << l
        elsif StatusMap[l['status']] == 'n'
          logs.last << l
        elsif content_unchanged(logs.last.last, l)
          logs.last << l
        else
          logs << [l]
        end
      }
      #pp logs.map {|ll| ll.map {|l| StatusMap[l['status']] + "#{l['checksum']}" } }

      logs[0...-1].each {|ll|
        ll.reject! {|l| StatusMap[l['status']] == 'n' }
        ll[1..-1] = [] if 2 <= ll.length
      }

      ll = logs.last
      ll.reject! {|l| StatusMap[l['status']] == 'n' } # removes `log' if it is 'n'.
      ll[1...-1] = [] if 2 < ll.length 
      if StatusMap[log['status']] == 'n'
        ll << log # re-add `log'.
      end

      nlogs = 2 # should be configurable?
      #pp logs.map {|ll| ll.map {|l| StatusMap[l['status']] + "#{l['checksum']}" } }
      if nlogs < logs.length
        logs[0...-nlogs] = []
      end
      #pp logs.map {|ll| ll.map {|l| StatusMap[l['status']] + "#{l['checksum']}" } }

      logseq.replace logs.flatten
    else
      raise "unrecognized log-status [bug]: #{StatusMap[log['status']].inspect}"
    end

    unless logseq.last.equal? log
      raise "current log is not added [bug]"
    end
  end

  def find_first_200_with_current_content
    result = nil
    @hash['_log'].reverse_each {|h|
      if h['status'] == '200'
        if !result
          result = h
        elsif !content_unchanged(result, h)
          return result
        else
          result = h
        end
      end
    }
    result
  end

  def find_last_200
    @hash['_log'].reverse_each {|h|
      return h if h['status'] == '200'
    }
    nil
  end

  def find_last_success # 200 or 304
    @hash['_log'].reverse_each {|h|
      return h if StatusMap[h['status']] != 'e'
    }
    nil
  end

  def find_first_error
    @hash['_log'].each {|h|
      return h if StatusMap[h['status']] == 'e'
    }
    nil
  end

  def find_last_error
    @hash['_log'].reverse_each {|h|
      return h if StatusMap[h['status']] == 'e'
    }
    nil
  end

  def presentation_data
    h = @config.dup
    log = @hash['_log']
    h.update @hash # xxx
    h['title'] = h['Title']
    h['author'] = h['Author']
    h['last-modified'] = '- no log -'
    unless log.empty?
      if l = find_first_200_with_current_content
        h['last-modified-found'] = l['clientDateBeg'] # xxx: clientDateEnd is better?
        if l.include? 'lastModifiedString'
          h['last-modified'] = Time.httpdate_robust(l['lastModifiedString']).localtime.iso8601
          l2 = find_last_200
          unless l.equal? l2
            if l['lastModifiedString'] != l2['lastModifiedString']
              h['last-modified'] << '[Touch]'
            else
              h['last-modified'] << '[NoIMS]'
            end
          end
        else
          h['last-modified'] = l['clientDateBeg'].getlocal.iso8601 + '[NoLM]'
        end
        h['title'] ||= l['extractedTitle'] if l['extractedTitle']
        h['author'] ||= l['extractedAuthor'] if l['extractedAuthor']
      else
        l = log.last
        if l['status']
          if l['statusMessage']
            h['last-modified'] = "- #{l['status']} #{l['statusMessage']} -"
          else
            h['last-modified'] = "- #{l['status']} -"
          end
        elsif l['trouble']
          h['last-modified'] = "- #{l['trouble']} -"
        else
          h['last-modified'] = '- no status -'
        end
      end
    end
    h['title'] ||= h['LinkURI'] if h['LinkURI']
    h['title'] ||= h['URI']

    h
  end

  def merge(hash)
    @hash = hash.dup.update(@hash)
  end
end

module Enumerable
  def concurrent_map(max_threads=8, &block)
    if max_threads == 1
      self.map(&block)
    else
      arr = self.to_a.dup
      queue = (0...arr.length).to_a

      max_threads = arr.length if arr.length < max_threads

      threads = []
      max_threads.times {
        threads << Thread.new {
          while i = queue.shift
            arr[i] = yield arr[i]
          end
        }
      }

      threads.each {|t| t.join }
      arr
    end
  end
end

class Webpecker
  def open_lock(filename, nonblock=false)
    dirname = File.dirname filename
    basename = File.basename filename
    tmpname = "#{dirname}/.,#{basename},#$$"

    1.times {
      begin
        target = File.open(filename, File::RDWR|File::CREAT)
        stat1 = target.stat
        if nonblock
          unless target.flock(File::LOCK_EX | File::LOCK_NB)
            STDERR.puts "fail to lock: #{filename}" if $VERBOSE
            return
          end
        else
          target.flock(File::LOCK_EX)
        end
        stat2 = File.stat(filename)
        redo if stat1.ino != stat2.ino

        begin
          File.open(tmpname, 'w') {|tmp|
            yield target, tmp
          }
          stat2 = File.stat(filename) # manually unlocked?
          File.rename(tmpname, filename) if stat1.ino == stat2.ino
        ensure
          File.unlink tmpname if FileTest.exist? tmpname
        end
      ensure
        target.close if target
      end
    }
  end

  def config_flatten(arr, default={})
    result = []
    arr.each {|elt|
      case elt
      when Hash
        if elt.include? 'URI'
          result << default.dup.update(elt)
        else
          default = default.dup.update(elt)
        end
      when Array
        result.concat config_flatten(elt, default)
      when String
        result << default.dup.update({'URI'=>elt})
      end
    }
    result
  end

  def deep_copy(o)
    Marshal.load(Marshal.dump(o))
  end

  def deep_freeze(o)
    objs = []
    o = Marshal.load(Marshal.dump(o), lambda {|obj| objs << obj })
    objs.each {|obj| obj.freeze }
    o
  end

  def load_config
    @configuration = {}
    config = config_flatten(File.open(CONFIG_FILENAME) {|f| YAML.load(f) })
    config.each {|h|
      h.reject! {|k, v| /\A[A-Z]/ !~ k }
      @configuration[h['URI']] = h
    }
    config
  end

  #def load_status(f) YAML.load(f) end
  #def save_status(f, d) f.puts d.to_yaml end
  def load_status(f) Marshal.load(f) end
  def save_status(d, f)
    Marshal.dump(d, f)
    AutoFile.clear
  end

  def open_status(readonly=false)
    if readonly
      open(STATUS_FILENAME) {|f|
        if f.stat.size == 0
          status = []
        else
          status = load_status(f)
        end
        status = deep_freeze(status)
        yield status
      }
    else
      open_lock(STATUS_FILENAME, true) {|f, out|
        if f.stat.size == 0
          status = []
        else
          status = load_status(f)
        end
        yield status
        save_status(status, out)
      }
    end
  end

  def generate_output(data)
    data = deep_copy(data)
    result = XTemplate::XMLTemplate.new(File.read(@opt_template).decode_charset_guess).expand(data)
    result.gsub!(/&apos;/, "'")
    if @opt_output != '-'
      dir = File.dirname @opt_output
      if FileTest.writable? dir
        output_new = @opt_output + '.new'
        open(output_new, 'w') {|f|
          f.puts result
        }
        File.rename output_new, @opt_output
      else
        open(@opt_output, 'w') {|f|
          f.puts result
        }
      end
    else
      puts result
    end
  end

  def parse_options
    @opt_output = OUTPUT_LATEST_FILENAME
    @opt_dont_check = nil
    @opt_force_check = nil
    @opt_timing = nil
    @opt_dump_config = nil
    @opt_dump_status = nil
    @opt_dump_template_data = nil
    @opt_template = TEMPLATE_LATEST_FILENAME
    @opt_remove_entry = nil
    ARGV.options {|q|
      q.banner = 'webpecker [opts]'
      q.def_option('--help', 'show this message') {puts q; exit(0)}
      q.def_option('--verbose', '-v', 'verbose') { $VERBOSE = true }
      q.def_option('--no-check', '-n', 'don\'t check web') { @opt_dont_check = true }
      q.def_option('--force', '-f', 'force check (avoid timing control mechanism)') { @opt_force_check = true }
      q.def_option('--output=filename', '-o', 'specify output file') {|filename| @opt_output = filename }
      q.def_option('--template=filename', '-T', 'specify template') {|filename| @opt_template = filename }
      q.def_option('--timing', '-t', 'show timings') { @opt_timing = true }
      q.def_option('--dump-config', 'dump flatten configuration') { @opt_dump_config = true }
      q.def_option('--dump-status', 'dump status') { @opt_dump_status = true }
      q.def_option('--dump-template-data', 'dump data for expand template') { @opt_dump_template_data = true }
      q.def_option('--remove-entry', 'remove entry') { @opt_remove_entry = true }
      q.parse!
    }
  end

  def dump_status(status)
    if ARGV.empty?
      status.each {|ent|
        pp ent
      }
    else
      status.each {|ent|
        c = @configuration[ent['URI']]
        pp ent if ARGV.include?(ent['URI']) || (c && ARGV.include?(c['LinkURI']))
      }
    end
  end

  def create_entries(config, status, readonly=false)
    logs = {}
    status.each {|status_ent|
      if status_ent.include?('URI') && status_ent.include?('_log')
        logs[status_ent['URI']] = status_ent['_log']
      end
    }

    status.clear unless readonly

    entries = []
    config.each {|config_ent|
      uri = config_ent['URI']
      log = logs[uri] || []
      status_ent = { 'URI' => uri, '_log' => log }
      status << status_ent unless readonly
      entries << Entry.new(status_ent, config_ent)
    }
    entries
  end

  def main
    parse_options
    config = load_config
    if @opt_dump_config
      puts config.to_yaml
      return
    end
    data = nil
    readonly = @opt_timing || @opt_dont_check || @opt_dump_status || @opt_dump_template_data
    open_status(readonly) {|status|
      if @opt_remove_entry
        status.reject! {|h| ARGV.include? h['URI'] } #xx: LinkURI, etc.
      elsif @opt_dump_status
        dump_status(status)
      else
        entries = create_entries(config, status, readonly)
        if @opt_timing
          entries = entries.map {|entry|
            [entry.next_timing.localtime, entry]
          }.sort
          now = Time.now
          entries.each {|timing, entry|
            if now && timing > now
              puts "#{now}  --- now ---"
              now = nil
            end
            h = entry.presentation_data
            s = "#{timing}: #{h['title']}"
            s << " (#{h['Author']})" if h['Author']
            puts s
          }
        else
          unless readonly
            entries.concurrent_map {|entry|
              next unless entry.update_info?
              entry.check if entry.should_check? && (@opt_force_check || entry.timing_check)
            }
            entries.concurrent_map {|entry|
              next if entry.update_info?
              entry.check if entry.should_check? && (@opt_force_check || entry.timing_check)
            }
          end
          entries.reject! {|entry| entry.update_info? }
          data = {
            "antenna" =>
            entries.map {|entry| entry.presentation_data }.sort_by {|h|
              # [h['last-modified'], h['title']]
              if h['last-modified-found']
                [1, h['last-modified-found'], h['last-modified'], h['title']]
              else
                [0, h['last-modified'], h['title']]
              end
            }.reverse
          }
          if @opt_dump_template_data
            pp data
            return
          end
          generate_output(data)
        end
      end
    }
    #PP.pp(data, STDERR) if $VERBOSE
  end

end

if $0 == __FILE__
  Webpecker.new.main
end
